{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RRA Climate Health","text":"<p>Documentation</p> <p>A collection of geospatial models examining the relationship between climate variables, socio-demographic indicators, and health outcomes.</p>"},{"location":"#setting-up-a-development-environment","title":"Setting up a development environment","text":"<ul> <li>Clone this repository</li> <li> <p>Create a conda environment with python and the R dependencies for the model.</p> <pre><code>conda create -n cgf -c conda-forge python=3.12 r r-base r-lmertest r-emmeans\n</code></pre> </li> <li> <p>Activate the conda environment</p> <pre><code>conda activate cgf\n</code></pre> </li> <li> <p>Use <code>pip</code> to install <code>poetry</code> in the conda environment</p> <pre><code>pip install poetry\n</code></pre> </li> <li> <p>Install the dependencies</p> <pre><code>poetry install\n</code></pre> </li> </ul>"},{"location":"#pre-commit","title":"Pre-commit","text":"<p>Pre-commit hooks run all the auto-formatting (<code>ruff format</code>), linters (e.g. <code>ruff</code> and <code>mypy</code>), and other quality  checks to make sure the changeset is in good shape before a commit/push happens.</p> <p>You can install the hooks with (runs for each commit):</p> <pre><code>pre-commit install\n</code></pre> <p>Or if you want them to run only for each push:</p> <pre><code>pre-commit install -t pre-push\n</code></pre> <p>Or if you want e.g. want to run all checks manually for all files:</p> <pre><code>pre-commit run --all-files\n</code></pre>"},{"location":"api_docs/","title":"API documentation","text":""},{"location":"api_docs/#rra_climate_health.cli","title":"<code>cli</code>","text":""},{"location":"api_docs/#rra_climate_health.cli.strun","title":"<code>strun() -&gt; None</code>","text":"<p>Entry point for running spatial-temporal CGF pipeline workflows.</p> Source code in <code>src/rra_climate_health/cli.py</code> <pre><code>@click.group()\ndef strun() -&gt; None:\n    \"\"\"Entry point for running spatial-temporal CGF pipeline workflows.\"\"\"\n</code></pre>"},{"location":"api_docs/#rra_climate_health.cli.sttask","title":"<code>sttask() -&gt; None</code>","text":"<p>Entry point for running spatial-temporal CGF pipeline tasks.</p> Source code in <code>src/rra_climate_health/cli.py</code> <pre><code>@click.group()\ndef sttask() -&gt; None:\n    \"\"\"Entry point for running spatial-temporal CGF pipeline tasks.\"\"\"\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data","title":"<code>data</code>","text":""},{"location":"api_docs/#rra_climate_health.data.get_run_directory","title":"<code>get_run_directory(output_root: str | Path) -&gt; Path</code>","text":"<p>Gets a path to a datetime directory for a new output.</p>"},{"location":"api_docs/#rra_climate_health.data.get_run_directory--parameters","title":"Parameters","text":"<p>output_root     The root directory for all outputs.</p> Source code in <code>src/rra_climate_health/data.py</code> <pre><code>def get_run_directory(output_root: str | Path) -&gt; Path:\n    \"\"\"Gets a path to a datetime directory for a new output.\n\n    Parameters\n    ----------\n    output_root\n        The root directory for all outputs.\n\n    \"\"\"\n    output_root = Path(output_root).resolve()\n    launch_time = datetime.datetime.now(tz=datetime.UTC).strftime(\"%Y_%m_%d\")\n    today_runs = [\n        int(run_dir.name.split(\".\")[1])\n        for run_dir in output_root.iterdir()\n        if run_dir.name.startswith(launch_time)\n    ]\n    run_version = max(today_runs) + 1 if today_runs else 1\n    datetime_dir = output_root / f\"{launch_time}.{run_version:0&gt;2}\"\n    return datetime_dir\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data.save_raster","title":"<code>save_raster(raster: rt.RasterArray, output_path: str | Path, num_cores: int = 1, **kwargs: typing.Any) -&gt; None</code>","text":"<p>Save a raster to a file with standard parameters.</p> Source code in <code>src/rra_climate_health/data.py</code> <pre><code>def save_raster(\n    raster: rt.RasterArray,\n    output_path: str | Path,\n    num_cores: int = 1,\n    **kwargs: typing.Any,\n) -&gt; None:\n    \"\"\"Save a raster to a file with standard parameters.\"\"\"\n    save_params = {\n        \"tiled\": True,\n        \"blockxsize\": 512,\n        \"blockysize\": 512,\n        \"compress\": \"ZSTD\",\n        \"predictor\": 2,  # horizontal differencing\n        \"num_threads\": num_cores,\n        \"bigtiff\": \"yes\",\n        **kwargs,\n    }\n    touch(output_path, exist_ok=True)\n    raster.to_file(output_path, **save_params)\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data_prep","title":"<code>data_prep</code>","text":""},{"location":"api_docs/#rra_climate_health.data_prep.run_inference_data_prep","title":"<code>run_inference_data_prep</code>","text":""},{"location":"api_docs/#rra_climate_health.data_prep.run_inference_data_prep.run_ldi_prep","title":"<code>run_ldi_prep(output_root: str, year: list[str], queue: str) -&gt; None</code>","text":"<p>Prep LDI rasters from admin2 data</p> Source code in <code>src/rra_climate_health/data_prep/run_inference_data_prep.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_year(allow_all=True)\n@clio.with_queue()\ndef run_ldi_prep(output_root: str, year: list[str], queue: str) -&gt; None:\n    \"\"\"Prep LDI rasters from admin2 data\"\"\"\n    jobmon.run_parallel(\n        runner=\"sttask\",\n        task_name=\"ldi_prep\",\n        node_args={\"year\": year},\n        task_args={\n            \"output-root\": output_root,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"35Gb\",\n            \"runtime\": \"1h\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        log_root=str(output_root),\n    )\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data_prep.run_inference_data_prep.run_ldi_prep_main","title":"<code>run_ldi_prep_main(output_root: str | Path, year: int) -&gt; None</code>","text":"<p>Run LDI data preparation.</p> Source code in <code>src/rra_climate_health/data_prep/run_inference_data_prep.py</code> <pre><code>def run_ldi_prep_main(\n    output_root: str | Path,\n    year: int,\n) -&gt; None:\n    \"\"\"Run LDI data preparation.\"\"\"\n    # Measure doesn't matter for this task\n    cm_data = ClimateMalnutritionData(Path(output_root) / \"stunting\")\n    print(\"Loading admin2 shapes and raster template\")\n    admin2 = cm_data.load_lbd_admin2_shapes()\n    raster_template = cm_data.load_raster_template()\n\n    print(\"Loading LDI data\")\n    ldi = pd.read_csv(upstream_paths.LDIPC_SUBNATIONAL_FILEPATH)\n    # Fill in missing values with national mean\n    national_mean = ldi.groupby(\n        [\"year_id\", \"national_ihme_loc_id\", \"population_percentile\"]\n    ).ldipc.transform(\"mean\")\n    null_mask = ldi.ldipc.isna()\n    ldi.loc[null_mask, \"ldipc\"] = national_mean.loc[null_mask]\n    # Convert to daily, and drop 0th percentile, which is just 0.\n    ldi[\"ldi_pc_pd\"] = ldi[\"ldipc\"] / 365.25\n    ldi = ldi[ldi.population_percentile &gt; 0]\n\n    print(\"Building shape map\")\n    ldi_locs = ldi[\"location_id\"].unique().tolist()\n    shape_map = (\n        admin2.loc[admin2.loc_id.isin(ldi_locs), [\"loc_id\", \"geometry\"]]\n        .rename(columns={\"loc_id\": \"location_id\"})\n        .set_index(\"location_id\")\n        .geometry\n    )\n\n    print(\"Rasterizing LDI data\")\n    percentiles = ldi[\"population_percentile\"].unique().tolist()\n    for percentile in percentiles:\n        print(f\"Rasterizing percentile: {percentile}\")\n        p_year_mask = (ldi.population_percentile == percentile) &amp; (ldi.year_id == year)\n        ldi_pc_pd = ldi.loc[p_year_mask].set_index(\"location_id\").ldi_pc_pd\n        ldi_pc_pd = ldi_pc_pd[~ldi_pc_pd.index.duplicated()]\n        shapes = [(shape_map.loc[loc], ldi_pc_pd.loc[loc]) for loc in ldi_pc_pd.index]\n        ldi_arr = rasterize(\n            shapes,\n            out=np.zeros_like(raster_template),\n            transform=raster_template.transform,\n        )\n        ldi_raster = rt.RasterArray(\n            ldi_arr,\n            transform=raster_template.transform,\n            crs=raster_template.crs,\n            no_data_value=np.nan,\n        )\n        cm_data.save_ldi_raster(ldi_raster, year, percentile)\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data_prep.run_inference_data_prep.run_ldi_prep_task","title":"<code>run_ldi_prep_task(output_root: str, year: str) -&gt; None</code>","text":"<p>Run LDI data preparation.</p> Source code in <code>src/rra_climate_health/data_prep/run_inference_data_prep.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_year()\ndef run_ldi_prep_task(output_root: str, year: str) -&gt; None:\n    \"\"\"Run LDI data preparation.\"\"\"\n    run_ldi_prep_main(Path(output_root), int(year))\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data_prep.run_training_data_prep","title":"<code>run_training_data_prep</code>","text":""},{"location":"api_docs/#rra_climate_health.data_prep.run_training_data_prep.run_training_data_prep","title":"<code>run_training_data_prep(output_root: str, source_type: str) -&gt; None</code>","text":"<p>Run training data prep.</p> Source code in <code>src/rra_climate_health/data_prep/run_training_data_prep.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_source_type(allow_all=False)\ndef run_training_data_prep(output_root: str, source_type: str) -&gt; None:\n    \"\"\"Run training data prep.\"\"\"\n    print(f\"Running training data prep for {source_type}...\")\n    # for src in source_type:\n    run_training_data_prep_main(output_root, source_type)\n</code></pre>"},{"location":"api_docs/#rra_climate_health.data_prep.upstream_paths","title":"<code>upstream_paths</code>","text":"<p>These are paths the RRA team does not own.</p> <p>They should only be accessed from the <code>data_prep</code> subpackage. Downstream pipeline code should depend on data we manage wherever practical and load that data using the <code>rra_climate_health.data</code> module.</p>"},{"location":"api_docs/#rra_climate_health.inference","title":"<code>inference</code>","text":""},{"location":"api_docs/#rra_climate_health.inference.run_inference","title":"<code>run_inference</code>","text":""},{"location":"api_docs/#rra_climate_health.inference.run_inference.forecast_scenarios_task","title":"<code>forecast_scenarios_task(output_root: str, measure: str, results_version: str, model_version: str) -&gt; None</code>","text":"<p>Run forecasting applying the inference results, and output diagnostics.</p> Source code in <code>src/rra_climate_health/inference/run_inference.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_measure()\n@clio.with_results_version()\n@clio.with_model_version()\ndef forecast_scenarios_task(\n    output_root: str,\n    measure: str,\n    results_version: str,\n    model_version: str,\n) -&gt; None:\n    \"\"\"Run forecasting applying the inference results, and output diagnostics.\"\"\"\n    forecast_scenarios(\n        Path(output_root),\n        measure,\n        results_version,\n    )\n    create_inference_diagnostics_report(\n        Path(output_root), measure, results_version, model_version\n    )\n</code></pre>"},{"location":"api_docs/#rra_climate_health.inference.run_inference.model_inference","title":"<code>model_inference(output_root: str, model_version: str, measure: str, cmip6_scenario: list[str], year: list[str], queue: str) -&gt; None</code>","text":"<p>Run model inference.</p> Source code in <code>src/rra_climate_health/inference/run_inference.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_model_version()\n@clio.with_measure()\n@clio.with_cmip6_scenario(allow_all=True)\n@clio.with_year(allow_all=True)\n@clio.with_queue()\ndef model_inference(\n    output_root: str,\n    model_version: str,\n    measure: str,\n    cmip6_scenario: list[str],\n    year: list[str],\n    queue: str,\n) -&gt; None:\n    \"\"\"Run model inference.\"\"\"\n    cm_data = ClimateMalnutritionData(Path(output_root) / measure)\n    results_version = cm_data.new_results_version(model_version)\n    print(\n        f\"Running inference for {measure} using {model_version}. Results version: {results_version}\"\n    )\n\n    jobmon.run_parallel(\n        runner=\"sttask\",\n        task_name=\"inference\",\n        node_args={\n            \"measure\": [measure],\n            \"cmip6-scenario\": cmip6_scenario,\n            \"year\": year,\n        },\n        task_args={\n            \"output-root\": output_root,\n            \"model-version\": model_version,\n            \"results-version\": results_version,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"90Gb\",\n            \"runtime\": \"240m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        log_root=str(cm_data.results / results_version),\n    )\n\n    jobmon.run_parallel(\n        runner=\"sttask\",\n        task_name=\"forecast\",\n        node_args={\n            \"measure\": [measure],\n        },\n        task_args={\n            \"output-root\": output_root,\n            \"model-version\": model_version,\n            \"results-version\": results_version,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 2,\n            \"memory\": \"30Gb\",\n            \"runtime\": \"30m\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        log_root=str(cm_data.results / results_version),\n    )\n    print(\n        f\"Inference complete, results can be found at {cm_data.results / results_version}\"\n    )\n</code></pre>"},{"location":"api_docs/#rra_climate_health.inference.run_inference.model_inference_task","title":"<code>model_inference_task(output_root: str, measure: str, results_version: str, model_version: str, cmip6_scenario: str, year: str) -&gt; None</code>","text":"<p>Run model inference.</p> Source code in <code>src/rra_climate_health/inference/run_inference.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_measure()\n@clio.with_results_version()\n@clio.with_model_version()\n@clio.with_cmip6_scenario()\n@clio.with_year()\ndef model_inference_task(\n    output_root: str,\n    measure: str,\n    results_version: str,\n    model_version: str,\n    cmip6_scenario: str,\n    year: str,\n) -&gt; None:\n    \"\"\"Run model inference.\"\"\"\n    model_inference_main(\n        Path(output_root),\n        measure,\n        results_version,\n        model_version,\n        cmip6_scenario,\n        int(year),\n    )\n</code></pre>"},{"location":"api_docs/#rra_climate_health.training","title":"<code>training</code>","text":""},{"location":"api_docs/#rra_climate_health.training.run_training","title":"<code>run_training</code>","text":""},{"location":"api_docs/#rra_climate_health.training.run_training.model_training","title":"<code>model_training(model_specification_path: str, output_root: str, queue: str) -&gt; None</code>","text":"<p>Run model training.</p> Source code in <code>src/rra_climate_health/training/run_training.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@click.argument(\n    \"model_specification_path\",\n    type=click.Path(exists=True),\n)\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_queue()\ndef model_training(\n    model_specification_path: str,\n    output_root: str,\n    queue: str,\n) -&gt; None:\n    \"\"\"Run model training.\"\"\"\n    model_spec = ModelSpecification.from_yaml(model_specification_path)\n    measure = model_spec.measure\n    measure_root = Path(output_root) / measure\n    cm_data = ClimateMalnutritionData(measure_root)\n    model_version = cm_data.new_model_version()\n    version_root = cm_data.models / model_version\n    model_spec.version.model = model_version\n    cm_data.save_model_specification(model_spec, model_version)\n\n    print(\"Runing model training for model version\", model_version)\n\n    jobmon.run_parallel(\n        runner=\"sttask\",\n        task_name=\"training\",\n        node_args={\n            \"age-group-id\": clio.VALID_AGE_GROUP_IDS,\n            \"sex-id\": clio.VALID_SEX_IDS,\n        },\n        task_args={\n            \"output-root\": output_root,\n            \"measure\": measure,\n            \"model-version\": model_version,\n        },\n        task_resources={\n            \"queue\": queue,\n            \"cores\": 1,\n            \"memory\": \"20Gb\",\n            \"runtime\": \"1h\",\n            \"project\": \"proj_rapidresponse\",\n        },\n        max_attempts=1,\n        log_root=str(version_root),\n    )\n\n    print(\"Model training complete. Results can be found at\", version_root)\n</code></pre>"},{"location":"api_docs/#rra_climate_health.training.run_training.model_training_task","title":"<code>model_training_task(output_root: str, measure: str, model_version: str, age_group_id: str, sex_id: str) -&gt; None</code>","text":"<p>Run model training.</p> Source code in <code>src/rra_climate_health/training/run_training.py</code> <pre><code>@click.command()  # type: ignore[arg-type]\n@clio.with_output_root(DEFAULT_ROOT)\n@clio.with_measure()\n@clio.with_model_version()\n@clio.with_age_group_id()\n@clio.with_sex_id()\ndef model_training_task(\n    output_root: str,\n    measure: str,\n    model_version: str,\n    age_group_id: str,\n    sex_id: str,\n) -&gt; None:\n    \"\"\"Run model training.\"\"\"\n    model_training_main(\n        Path(output_root),\n        measure,\n        model_version,\n        int(age_group_id),\n        int(sex_id),\n    )\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"inference/","title":"Inference","text":"<p>While we train using individual observations under specific climate and income circumstances, we forecast prevalences and counts for the whole planet. This discrepancy means that, in order to produce predictions, we need to manually build the prediction for every individual pixel in the globe's representation.</p> <p>Inference takes as input the coefficients from the trained model, climate forecasts for a given scenario, and income forecasts. In order to estimate prevalence for a given pixel, we take the coefficients of the climate variables and apply them to the values for the climate variables for the given scenario. Since income is given in a distribution with 10 deciles, we create an estimate for each decile in the pixel and add them up.</p> <p>In order to get a region's prevalence, we need a measure of the distribution of the population. Currently, we're using a static 2020 population raster from the Global Human Settlement Layer and calculate the proportion of population living in a given pixel and hold it static throughout the estimation period. We aggregate the region's pixel's prevalences to produce a single region's prevalence. In order to produce counts and wider prevalences, we use a region-specific population forecast.</p>"},{"location":"inputs/","title":"Survey Data Inputs","text":"<p>We use the DHS Surveys as our main source of linking a malnutrition outcome to a given zone (for climate) and household (for income).</p> <p>There are three extractions that we source from:</p> <ul> <li>An extraction from the <code>anthropometrics</code> codebook, purported to have the same inputs as gbd does (from DHS)</li> <li>An extraction from the wealth team</li> <li>An extraction from the LSAE team</li> </ul> <p>We link the LSAE and wealth extractions by NID, household id and year, performing cleaning where necessary, as some surveys have the strata as part of the household id, and some don't. The source of the heterogeneity in inputs given that they are coming from the same source hasn't been established.</p>"},{"location":"inputs/#income-asset-matching","title":"Income - Asset matching","text":"<p>In order to forecast using income, we need to transform the DHS Asset Index into a measure of income. We use Joe Dieleman's team's distributions of income. To do that, for a given NID (that is, for a given location-year_start), we look at the unique households sampled in the survey (if there is more than one observation in the same household, we take them to experience the same income). We weight each household by the reported DHS observation weight to have an asset index distribution. We calculate to what percentile each household's asset index corresponds and we match it to the corresponding percentiles in the income distribution. We receive the income distributions in increments of 0.1 density, however. In order to match the percentile, we interpolate using monotonic cubic splines.</p> <p>However, the income distributions and asset distributions often don't have the same shape. We assume this is because the DHS surveys are unlikely to truly sample the very upper ends of the income distribution. Hence, we need fit the DHS asset distribution to a more appropriate income distribution. We do that by testing different thresholds for cutting off the upper end of the income distribution, comparing the two distributions (in a scaled CDF space) and choosing the one that minimizes the absolute sum in the difference between the distributions.</p>"},{"location":"inputs/#climate-variables","title":"Climate variables","text":"<p>We use the reported geographical coordinates in the DHS survey \u2013even though they refer to the location of the PSU\u2013 to map the correct climate conditions for the household for all the available climate variables such as mean temperature, days above 30C, and precipitation.</p> <p>We also use those coordinates to triangulate the altitude / elevation of the household.</p>"},{"location":"model/","title":"Model Specification","text":"<p>We use a mixed methods logistic regression. The objective is to estimate the effect of climate variables, income and other covariates on a given health outcome.</p> <p>The tool allows for the following: - Choosing to use age groups and sex as either categorical variables or to do submodels by either or both of them. - Using any of the climate variables available - Random effects on the intercept by location - either country-level or FHS admin-2 levels - Income - Other variables: SDI, year - Interaction between a threshold climate variable and income Other rasterized variables can be added with a few code changes. Non-rasterized variables need to be rasterized first if they vary geographically (such as country-specific variables).</p> <p>Model covariates can be expressed to undergo transformations from the raw state. These can be: - Scaling   - Min Max   - Standardizing   - Inner 95: Scale but setting the top and bottom values at the 0.25 and 0.975 percentile of the covariate values' distribution - Binning - Masking</p> <p>In order to specify all these, refer to the example model specifications.</p> <p>Model training follows the specification provided, transforms the data and feeds it to a Lmer model.</p>"}]}