{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport cgf_utils\n",
    "%aimport mf\n",
    "%aimport paths\n",
    "%aimport income_funcs\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import rasterra as rt\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from pymer4 import Lmer\n",
    "import glob\n",
    "import logging\n",
    "import pickle\n",
    "import sys\n",
    "import logging\n",
    "from scipy.special import expit\n",
    "\n",
    "from location_mapping import load_fhs_lsae_mapping\n",
    "#from income_funcs import load_binned_income_distribution_proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_POPULATION_FILEPATH = '/mnt/team/rapidresponse/pub/population/data/01-raw-data/other-gridded-pop-projects/global-human-settlement-layer/2020/GHS_POP_E2020_GLOBE_R2023A_4326_30ss_V1_0.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = 'stunting'\n",
    "fhs_location_id = 573 #98 #Chile\n",
    "scenario = 'ssp119'\n",
    "year_id = 2022\n",
    "sex_id = 2\n",
    "age_group_id = 4\n",
    "model_identifier = 'tempgrid_o30'#'re_grid_o30'\n",
    "#model_filepath = paths.MODEL_ROOTS / model_identifier / f'model_{measure}_{age_group_id}_{sex_id}.pkl'\n",
    "\n",
    "# model_filepath = '/mnt/team/rapidresponse/pub/population/modeling/climate_malnutrition/output/models/model.pkl'\n",
    "# with open(model_filepath, 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /mnt/team/rapidresponse/pub/population/modeling/climate_malnutrition/output/models/tempgrid_o30/model_stunting_5_1.pkl\n",
      "Loading /mnt/team/rapidresponse/pub/population/modeling/climate_malnutrition/output/models/tempgrid_o30/model_stunting_4_1.pkl\n",
      "Loading /mnt/team/rapidresponse/pub/population/modeling/climate_malnutrition/output/models/tempgrid_o30/model_stunting_4_2.pkl\n",
      "Loading /mnt/team/rapidresponse/pub/population/modeling/climate_malnutrition/output/models/tempgrid_o30/model_stunting_5_2.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>affected_proportion</th>\n",
       "      <th>year_id</th>\n",
       "      <th>scenario</th>\n",
       "      <th>measure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fhs_location_id</th>\n",
       "      <th>age_group_id</th>\n",
       "      <th>sex_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">573.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>1</th>\n",
       "      <td>0.293676</td>\n",
       "      <td>2022</td>\n",
       "      <td>ssp119</td>\n",
       "      <td>stunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.217817</td>\n",
       "      <td>2022</td>\n",
       "      <td>ssp119</td>\n",
       "      <td>stunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>1</th>\n",
       "      <td>0.428143</td>\n",
       "      <td>2022</td>\n",
       "      <td>ssp119</td>\n",
       "      <td>stunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.377182</td>\n",
       "      <td>2022</td>\n",
       "      <td>ssp119</td>\n",
       "      <td>stunting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     affected_proportion  ...   measure\n",
       "fhs_location_id age_group_id sex_id                       ...          \n",
       "573.0           4            1                  0.293676  ...  stunting\n",
       "                             2                  0.217817  ...  stunting\n",
       "                5            1                  0.428143  ...  stunting\n",
       "                             2                  0.377182  ...  stunting\n",
       "\n",
       "[4 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%aimport fhs_prediction\n",
    "# get_predictions(measure, fhs_location_id, scenario, year, model_identifier):\n",
    "\n",
    "fhs_prediction.get_predictions(measure, fhs_location_id, scenario, year_id, model_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhs_location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_family(model_identifier, measure):\n",
    "    import glob\n",
    "    import re\n",
    "    folder_path = paths.MODEL_ROOTS / model_identifier \n",
    "    glob_pattern = f\"{folder_path}/model_*_*.pkl\"\n",
    "    pattern = re.compile(f\"model_{measure}_\" + r\"(\\d+)_(\\d+)\\.pkl\")\n",
    "    models = []\n",
    "\n",
    "    for filepath in folder_path.glob(\"model_*_*.pkl\"):\n",
    "        match = pattern.match(filepath.name) \n",
    "        if match:\n",
    "            # Extract X and Y from the filename\n",
    "            age_group_id, sex_id = match.groups()\n",
    "            with open(filepath, 'rb') as f:\n",
    "                models.append({'model': pickle.load(f), 'age_group_id': age_group_id, 'sex_id': sex_id})\n",
    "        else:\n",
    "            raise ValueError(f\"Filename {filename} does not match the pattern {pattern.pattern}\")\n",
    "    return model_spec\n",
    "\n",
    "def scale_like_input_data(to_scale, input_min, input_max):\n",
    "    return (to_scale - input_min) / (input_max - input_min)\n",
    "\n",
    "def reverse_scaling(X_scaled, original_min, original_max, scaled_min, scaled_max):\n",
    "    X_std = (X_scaled - scaled_min) / (scaled_max - scaled_min)\n",
    "    X_original = X_std * (original_max - original_min) + original_min\n",
    "    return X_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_mapping = load_fhs_lsae_mapping(fhs_location_id)\n",
    "fhs_shapefile = loc_mapping.iloc[0].fhs_shape\n",
    "location_iso3 = loc_mapping.iloc[0].worldpop_iso3\n",
    "simple_loc_mapping = loc_mapping[['fhs_location_id', 'lsae_location_id']]\n",
    "income_df = income_funcs.load_binned_income_distribution_proportions(fhs_location_id=fhs_location_id, measure= measure, year_id = year_id) #and year\n",
    "\n",
    "models = get_model_family(model_identifier, measure)\n",
    "model = models[0]['model'] #getting the first model to base bins and variable info off of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhs_pop_raster = rt.load_raster(GLOBAL_POPULATION_FILEPATH, fhs_shapefile.bounds).set_no_data_value(np.nan)\n",
    "fhs_pop_raster = fhs_pop_raster.clip(fhs_shapefile)\n",
    "\n",
    "possible_climate_variables = ['temp', 'precip', 'over_30']\n",
    "climate_vars_to_match_bins = [v for v in model.vars_to_bin if v in possible_climate_variables]\n",
    "continuous_climate_vars = [v for v in ['temp', 'over_30'] if (v in possible_climate_variables) and (v not in climate_vars_to_match_bins) and (v in model.model_vars)]\n",
    "climate_vars = [x for x in possible_climate_variables if x in set(model.model_vars + model.vars_to_bin)]\n",
    "\n",
    "climate_rasters = {}\n",
    "for var in climate_vars:\n",
    "    climate_rasters[var] = mf.get_climate_variable_raster(scenario, year_id, var, None, None, untreated=True)\n",
    "    climate_rasters[var] = climate_rasters[var].resample_to(fhs_pop_raster).clip(fhs_shapefile)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_climate_variable_raster(location_iso3, scenario, year, climate_var, shapefile, reference_raster, nodata = np.nan, untreated=False):\n",
    "\n",
    "admin_dfs = []\n",
    "for _, admin2_row in loc_mapping.iterrows():\n",
    "    lsae_location_id = admin2_row.lsae_location_id\n",
    "    lsae_shapefile = admin2_row.lsae_shape\n",
    "\n",
    "    pop_raster = fhs_pop_raster.clip(lsae_shapefile).mask(lsae_shapefile)\n",
    "    pop_array = pop_raster.set_no_data_value(np.nan).to_numpy()\n",
    "\n",
    "    rasters = {'population': pop_array.flatten()}\n",
    "\n",
    "    for var in climate_vars_to_match_bins:\n",
    "        climate_raster = climate_rasters[var].clip(lsae_shapefile).mask(lsae_shapefile)\n",
    "        climate_array = climate_raster.to_numpy()\n",
    "        assert pop_array.shape == climate_array.shape\n",
    "        binned_climate_array = np.digitize(climate_array, model.var_info[var]['bin_edges'], right=False) - 1\n",
    "        rasters[var+'_bin_idx'] = binned_climate_array.flatten()\n",
    "\n",
    "    #climate_raster = big_climate_raster.clip(lsae_shapefile).mask(lsae_shapefile)#.resample_to(pop_raster)\n",
    "    for var in continuous_climate_vars:\n",
    "        climate_raster = climate_rasters[var].clip(lsae_shapefile).mask(lsae_shapefile)\n",
    "        climate_array = climate_raster.to_numpy()\n",
    "        assert pop_array.shape == climate_array.shape\n",
    "        rasters[var] = climate_array.flatten()\n",
    "\n",
    "    # Alternative approach is to group pixels to lsae\n",
    "    #temp_df = pd.DataFrame({'pop': pop_array.flatten(), 'climate_bin_idx': binned_climate_array.flatten()}).groupby('climate_bin_idx', as_index=False).pop.sum()\n",
    "    # Keeping it as pixels\n",
    "    pixels_df = pd.DataFrame(rasters)\n",
    "    pixels_df = pixels_df.dropna(subset=['population'])\n",
    "    pixels_df['lsae_pop'] = np.nansum(pop_array)\n",
    "    pixels_df['lsae_location_id'] = lsae_location_id\n",
    "    pixels_df['worldpop_iso3'] = admin2_row.worldpop_iso3\n",
    "\n",
    "    local_income_df = income_df.query('lsae_location_id == @lsae_location_id')\n",
    "    for var in climate_vars_to_match_bins:\n",
    "        pixels_df = pixels_df.merge(model.var_info[var]['bins'], left_on=var+'_bin_idx', right_index=True, how='inner')\n",
    "    pixels_df = pixels_df.merge(local_income_df, on='lsae_location_id', how='left')\n",
    "\n",
    "    # The lines from now on have coefficients and so are age_group and sex_id - specific\n",
    "    # Parallelizing by them could happen here - These can be precomputed for a model\n",
    "    for m in models:\n",
    "        model = m['model']\n",
    "        px_for_model_df = pixels_df.copy()\n",
    "        model.var_info['ihme_loc_id']['coefs'].rename(columns={'ihme_loc_id': 'worldpop_iso3'}, inplace=True)\n",
    "        \n",
    "        if model.has_grid:\n",
    "            px_for_model_df = px_for_model_df.merge(model.grid_spec['grid_definition'], how='left')\n",
    "            px_for_model_df = px_for_model_df.merge(model.var_info['grid_cell']['coefs'], how='left')\n",
    "\n",
    "        for var in continuous_climate_vars:\n",
    "            assert(len(model.var_info[var]['coefs'].columns) == 1)\n",
    "            colname = model.var_info[var]['coefs'].columns[0]\n",
    "            px_for_model_df[colname] = model.var_info[var]['coefs'][colname].item()\n",
    "\n",
    "        px_for_model_df = px_for_model_df.merge(model.var_info['ihme_loc_id']['coefs'], how='left', on='worldpop_iso3') \n",
    "        px_for_model_df.ihme_loc_id_coef = px_for_model_df.ihme_loc_id_coef.fillna(0)\n",
    "        \n",
    "        #build the logistic input one variable at a time\n",
    "        px_for_model_df['logistic_input'] = model.var_info['intercept']['coef']\n",
    "        px_for_model_df['logistic_input'] += px_for_model_df['ihme_loc_id_coef']\n",
    "        for var in climate_vars_to_match_bins:\n",
    "            if var in model.grid_spec['grid_order']: continue\n",
    "            px_for_model_df['logistic_input'] += px_for_model_df[var+'_bin_coef']\n",
    "        for var in continuous_climate_vars:\n",
    "            px_for_model_df['logistic_input'] += px_for_model_df[var+'_coef']\n",
    "        if model.has_grid:\n",
    "            px_for_model_df['logistic_input'] += px_for_model_df['grid_cell_coef']\n",
    "        px_for_model_df['prediction'] = expit(px_for_model_df['logistic_input'])\n",
    "        px_for_model_df['age_group_id'] = m['age_group_id']\n",
    "        px_for_model_df['sex_id'] = m['sex_id']\n",
    "        admin_dfs.append(px_for_model_df)\n",
    "\n",
    "fhs_df = pd.concat(admin_dfs)\n",
    "#24s to 92s\n",
    "#2:27 to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhs_df['population_at_income'] = fhs_df['population'] * fhs_df['proportion_at_income']\n",
    "fhs_df['population_proportion_at_income'] = fhs_df['population_at_income'] / fhs_df['lsae_pop'] / len(loc_mapping)\n",
    "fhs_df['affected_proportion'] = fhs_df['population_proportion_at_income'] * fhs_df['prediction']\n",
    "\n",
    "result_df = fhs_df.groupby(['fhs_location_id', 'age_group_id', 'sex_id']).agg(susceptible_proportion = ('population_proportion_at_income', 'sum'), affected_proportion = ('affected_proportion', 'sum'))\n",
    "result_df['year_id'] = year_id\n",
    "result_df['scenario'] = scenario\n",
    "result_df['measure'] = measure\n",
    "\n",
    "return result_df\n",
    "\n",
    "#return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
